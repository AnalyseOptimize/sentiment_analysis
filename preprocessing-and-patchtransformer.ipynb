{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:01.653951Z",
     "iopub.status.busy": "2025-05-29T18:14:01.653598Z",
     "iopub.status.idle": "2025-05-29T18:14:09.635569Z",
     "shell.execute_reply": "2025-05-29T18:14:09.634248Z",
     "shell.execute_reply.started": "2025-05-29T18:14:01.653918Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting apimoex\n",
      "  Downloading apimoex-1.4.0-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pandas-market-calendars\n",
      "  Downloading pandas_market_calendars-5.1.0-py3-none-any.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.11/dist-packages (from apimoex) (2.32.3)\n",
      "Requirement already satisfied: pandas>=1.1 in /usr/local/lib/python3.11/dist-packages (from pandas-market-calendars) (2.2.3)\n",
      "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from pandas-market-calendars) (2025.2)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from pandas-market-calendars) (2.9.0.post0)\n",
      "Collecting exchange-calendars>=3.3 (from pandas-market-calendars)\n",
      "  Downloading exchange_calendars-4.10.1-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas-market-calendars) (1.26.4)\n",
      "Collecting pyluach (from exchange-calendars>=3.3->pandas-market-calendars)\n",
      "  Downloading pyluach-2.2.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: toolz in /usr/local/lib/python3.11/dist-packages (from exchange-calendars>=3.3->pandas-market-calendars) (1.0.0)\n",
      "Collecting korean_lunar_calendar (from exchange-calendars>=3.3->pandas-market-calendars)\n",
      "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1->pandas-market-calendars) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil->pandas-market-calendars) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.31.0->apimoex) (2025.4.26)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (2025.1.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (2022.1.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->exchange-calendars>=3.3->pandas-market-calendars) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->exchange-calendars>=3.3->pandas-market-calendars) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->exchange-calendars>=3.3->pandas-market-calendars) (2022.1.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->exchange-calendars>=3.3->pandas-market-calendars) (1.3.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->exchange-calendars>=3.3->pandas-market-calendars) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->exchange-calendars>=3.3->pandas-market-calendars) (2024.2.0)\n",
      "Downloading apimoex-1.4.0-py3-none-any.whl (11 kB)\n",
      "Downloading pandas_market_calendars-5.1.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.9/123.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading exchange_calendars-4.10.1-py3-none-any.whl (200 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
      "Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: korean_lunar_calendar, pyluach, apimoex, exchange-calendars, pandas-market-calendars\n",
      "Successfully installed apimoex-1.4.0 exchange-calendars-4.10.1 korean_lunar_calendar-0.3.1 pandas-market-calendars-5.1.0 pyluach-2.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install apimoex pandas-market-calendars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:09.637109Z",
     "iopub.status.busy": "2025-05-29T18:14:09.636722Z",
     "iopub.status.idle": "2025-05-29T18:14:10.856137Z",
     "shell.execute_reply": "2025-05-29T18:14:10.855011Z",
     "shell.execute_reply.started": "2025-05-29T18:14:09.637063Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from datetime import datetime as extra_datetime\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "import requests\n",
    "import apimoex\n",
    "import time\n",
    "import pandas_market_calendars as mcal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:10.859030Z",
     "iopub.status.busy": "2025-05-29T18:14:10.858614Z",
     "iopub.status.idle": "2025-05-29T18:14:10.866441Z",
     "shell.execute_reply": "2025-05-29T18:14:10.865003Z",
     "shell.execute_reply.started": "2025-05-29T18:14:10.859002Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    \"SBER\",\n",
    "    \"TGLD\",   # Сбербанк\n",
    "    \"GAZP\",   # Газпром\n",
    "    \"LKOH\",   # Лукойл\n",
    "    \"PIKK\",   # Роснефть\n",
    "    \"SNGS\",   # Сургутнефтегаз\n",
    "    \"CHMF\",   # Северсталь\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:10.868814Z",
     "iopub.status.busy": "2025-05-29T18:14:10.868351Z",
     "iopub.status.idle": "2025-05-29T18:14:10.912025Z",
     "shell.execute_reply": "2025-05-29T18:14:10.910539Z",
     "shell.execute_reply.started": "2025-05-29T18:14:10.868775Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def parse_tickers(companies, start_date, end_date):\n",
    "    '''\n",
    "    companies: list, список тикеров \n",
    "    start_date: str, Дата вида ГГГГ-ММ-ДД\n",
    "    end_date: Дата вида ГГГГ-ММ-ДД\n",
    "    \n",
    "    '''\n",
    "    # Парсятся данные в основном режиме торгов T+2\n",
    "    board = 'TQBR'\n",
    "    dfs = []\n",
    "    with requests.Session() as session:\n",
    "        for ticker in tqdm(companies, desc = 'Processing russian stock', total = len(companies)):\n",
    "            \n",
    "            \n",
    "            data = apimoex.get_board_history(session, ticker, board=board,\n",
    "                                            start = start_date, end = end_date)\n",
    "\n",
    "            if data == []:\n",
    "                print(f\"Для акции {ticker} нет данных\")\n",
    "                continue\n",
    "            \n",
    "            data = pd.DataFrame(data)[[\"TRADEDATE\", \"CLOSE\"]]\n",
    "            data[\"TRADEDATE\"] = pd.to_datetime(data[\"TRADEDATE\"])\n",
    "            data.set_index(\"TRADEDATE\", inplace = True)\n",
    "            data.columns = [f\"close_{ticker}\"]\n",
    "            \n",
    "            dfs.append(data)\n",
    "    return pd.concat(dfs, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:10.913755Z",
     "iopub.status.busy": "2025-05-29T18:14:10.913267Z",
     "iopub.status.idle": "2025-05-29T18:14:13.579805Z",
     "shell.execute_reply": "2025-05-29T18:14:13.578684Z",
     "shell.execute_reply.started": "2025-05-29T18:14:10.913716Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fceed0da9ed74cbc99b600c0d82af07c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing russian stock:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Для акции TGLD нет данных\n"
     ]
    }
   ],
   "source": [
    "df = parse_tickers(tickers, \"2023-05-05\", \"2025-05-07\")\n",
    "df.ffill(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:13.581626Z",
     "iopub.status.busy": "2025-05-29T18:14:13.581051Z",
     "iopub.status.idle": "2025-05-29T18:14:13.589220Z",
     "shell.execute_reply": "2025-05-29T18:14:13.588086Z",
     "shell.execute_reply.started": "2025-05-29T18:14:13.581586Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:14:13.590577Z",
     "iopub.status.busy": "2025-05-29T18:14:13.590258Z",
     "iopub.status.idle": "2025-05-29T18:14:13.618353Z",
     "shell.execute_reply": "2025-05-29T18:14:13.617319Z",
     "shell.execute_reply.started": "2025-05-29T18:14:13.590541Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df[\"day\"] = df[\"TRADEDATE\"].map(lambda x: x.dayofweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_tgld = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/TGLD_comments_final.csv\")\n",
    "df_sngs = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/SNGS_comments_final.csv\")\n",
    "df_lkoh = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/LKOH_comments_final.csv\")\n",
    "df_gazp = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/GAZP_comments_final.csv\")\n",
    "df_chmf = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/CHMF_comments_final.csv\")\n",
    "df_sber = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/SBER_comments_final.csv\")\n",
    "df_pikk = pd.read_csv(\"/kaggle/input/tinkoff-pulse-parsing/PIKK_comments_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def align_comments_with_prices(df_comments, df_prices, price_col, l=20):\n",
    "    '''\n",
    "    Каждому комментарию в момент T сопоставляет цену p_T, если T < 18:50:00\n",
    "    и p_T+1 иначе. Для выходных сопоставляется цена закрытия в пн. \n",
    "\n",
    "    Каждой строке добавляет фичи от пользователя (агрегированные)\n",
    "    Добавляет историю цен, т.е. l лагов\n",
    "    '''\n",
    "    df_prices = df_prices.copy()\n",
    "    df_comments = df_comments.copy()\n",
    "    \n",
    "    df_prices['TRADEDATE'] = pd.to_datetime(df_prices['TRADEDATE'])\n",
    "    df_comments['inserted'] = pd.to_datetime(df_comments['inserted'])\n",
    "\n",
    "    tradedates = sorted(df_prices['TRADEDATE'].unique())\n",
    "\n",
    "    def match_tradedate(row):\n",
    "        inserted = row['inserted']\n",
    "        weekday = inserted.weekday()\n",
    "        date = inserted.date()\n",
    "        time = inserted.time()\n",
    "        if weekday >= 5:\n",
    "            for d in tradedates:\n",
    "                if d > pd.Timestamp(date):\n",
    "                    return d\n",
    "            return None\n",
    "        border_time = pd.to_timedelta('18:50:00')\n",
    "        if pd.to_timedelta(str(time)) < border_time:\n",
    "            for d in tradedates:\n",
    "                if d == pd.Timestamp(date):\n",
    "                    return d\n",
    "            for d in tradedates:\n",
    "                if d > pd.Timestamp(date):\n",
    "                    return d\n",
    "            return None\n",
    "        else:\n",
    "            for d in tradedates:\n",
    "                if d > pd.Timestamp(date):\n",
    "                    return d\n",
    "            return None\n",
    "\n",
    "    df_comments['TRADEDATE'] = df_comments.apply(match_tradedate, axis=1)\n",
    "    \n",
    "    comment_counts = (\n",
    "        df_comments.groupby('TRADEDATE')\n",
    "        .size()\n",
    "        .rename('total_posts')\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_comments = pd.merge(df_comments, comment_counts, on='TRADEDATE', how='left')\n",
    "\n",
    "    # === Лаги цен ===\n",
    "    for i in range(1, l + 1):\n",
    "        lag_col = f\"{price_col}_lag{i}\"\n",
    "        df_prices[lag_col] = df_prices[price_col].shift(i)\n",
    "\n",
    "    lag_cols = [f\"{price_col}_lag{i}\" for i in range(1, l + 1)]\n",
    "    price_cols = [price_col] + lag_cols\n",
    "\n",
    "    df_merged = pd.merge(df_comments, df_prices[['TRADEDATE'] + price_cols], on='TRADEDATE', how='left')\n",
    "\n",
    "    df_merged[\"hour\"] = df_merged[\"inserted\"].map(lambda x: x.hour)\n",
    "    \n",
    "    # Средние реакции на комментарии пользователя\n",
    "    mean_reactions = (\n",
    "        df_merged.groupby('nickname')['reactions']\n",
    "        .mean()\n",
    "        .rename('mean_reactions_per_user')\n",
    "        .reset_index()\n",
    "    )\n",
    "    df_merged = pd.merge(df_merged, mean_reactions, on='nickname', how='left')\n",
    "\n",
    "    # Переименование столбцов цен\n",
    "    rename_dict = {price_col: \"close\"}\n",
    "    for i in range(1, l + 1):\n",
    "        rename_dict[f\"{price_col}_lag{i}\"] = f\"close_lag{i}\"\n",
    "    df_merged = df_merged.rename(columns=rename_dict)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "df_gazp_aligned = align_comments_with_prices(df_gazp, df, 'close_GAZP', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n",
    "df_sngs_aligned = align_comments_with_prices(df_sngs, df, 'close_SNGS', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n",
    "df_pikk_aligned = align_comments_with_prices(df_pikk, df, 'close_PIKK', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n",
    "df_chmf_aligned = align_comments_with_prices(df_chmf, df, 'close_CHMF', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n",
    "df_lkoh_aligned = align_comments_with_prices(df_lkoh, df, 'close_LKOH', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n",
    "df_sber_aligned = align_comments_with_prices(df_sber, df, 'close_CHMF', l = 20).drop(['Unnamed: 0.1', 'Unnamed: 0', 'id', 'inserted', 'nickname', 'text', 'TRADEDATE'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PatchTST without sentiment (pretrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pip install transformers torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:18:52.420321Z",
     "iopub.status.busy": "2025-05-29T18:18:52.419956Z",
     "iopub.status.idle": "2025-05-29T18:18:52.442480Z",
     "shell.execute_reply": "2025-05-29T18:18:52.441591Z",
     "shell.execute_reply.started": "2025-05-29T18:18:52.420297Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import PatchTSTForPrediction, PatchTSTConfig\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def preprocess_data(df, price_col, time_col, seq_len = 20, prediction_length = 1, test_size = 0.2):\n",
    "    df = df.copy().sort_values(time_col)\n",
    "    values = df[price_col].diff().dropna().values.astype(np.float32) # ключевой аспект - переход от цен к доходностям! r_t = (p_t - p_t-1) / p_t-1\n",
    "\n",
    "    # масштабирование только по обучающей выборке (для стабилизации обучения)\n",
    "    n = int(len(values[seq_len:]) * test_size)\n",
    "    mean = values[:n].mean()\n",
    "    std = values[:n].std()\n",
    "\n",
    "    values = (values - mean) / std\n",
    "    \n",
    "\n",
    "    X, y = [], []\n",
    "    for i in range(len(values) - seq_len - prediction_length + 1):\n",
    "        X.append(values[i:i+seq_len].reshape(-1, 1))\n",
    "        y.append(values[i+seq_len:i+seq_len+prediction_length]) \n",
    "    \n",
    "    X = np.stack(X)  # (samples, seq_len, 1)\n",
    "    y = np.stack(y).reshape(-1, prediction_length)  # (samples, pred_len)\n",
    "\n",
    "    X = torch.tensor(X, dtype = torch.float32)\n",
    "    y = torch.tensor(y, dtype = torch.float32)\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, random_state=42, shuffle = False)\n",
    "\n",
    "\n",
    "    return X_train, X_val, y_train, y_val, mean, std\n",
    "\n",
    "X_train, X_val, y_train, y_val, mean, std = preprocess_data(df, \"close_GAZP\", \"TRADEDATE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:19:03.266085Z",
     "iopub.status.busy": "2025-05-29T18:19:03.265696Z",
     "iopub.status.idle": "2025-05-29T18:19:03.273057Z",
     "shell.execute_reply": "2025-05-29T18:19:03.272051Z",
     "shell.execute_reply.started": "2025-05-29T18:19:03.266039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "val_ds = TensorDataset(X_val, y_val)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T18:19:04.280007Z",
     "iopub.status.busy": "2025-05-29T18:19:04.279638Z",
     "iopub.status.idle": "2025-05-29T18:19:04.287957Z",
     "shell.execute_reply": "2025-05-29T18:19:04.286703Z",
     "shell.execute_reply.started": "2025-05-29T18:19:04.279977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:00:40.783396Z",
     "iopub.status.busy": "2025-05-29T19:00:40.783010Z",
     "iopub.status.idle": "2025-05-29T19:00:40.797015Z",
     "shell.execute_reply": "2025-05-29T19:00:40.795990Z",
     "shell.execute_reply.started": "2025-05-29T19:00:40.783368Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error, mean_absolute_error\n",
    "\n",
    "def pretrain_model(model, train_dl, val_dl, num_epochs, lr = 1e-3):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    val_loss_min = np.inf\n",
    "    \n",
    "    epoch_train_losses = []\n",
    "    epoch_val_losses = []\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Epochs\"):\n",
    "        model.train()\n",
    "        train_losses = []\n",
    "        for xb, yb in train_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            outputs = model(xb)\n",
    "            preds = outputs.prediction_outputs.squeeze(-1)\n",
    "            loss = loss_fn(preds, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            train_losses.append(loss.item())\n",
    "        train_loss_mean = np.mean(train_losses)\n",
    "        epoch_train_losses.append(train_loss_mean)\n",
    "        \n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dl:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                outputs = model(xb)\n",
    "                preds = outputs.prediction_outputs.squeeze(-1).cpu().numpy()\n",
    "                all_preds.append(preds)\n",
    "                all_targets.append(yb.cpu().numpy())\n",
    "        y_pred = np.concatenate(all_preds).ravel()\n",
    "        y_true = np.concatenate(all_targets).ravel()\n",
    "        val_loss = mean_squared_error(y_true, y_pred)\n",
    "        epoch_val_losses.append(val_loss)\n",
    "        \n",
    "        if (epoch % 10 == 0):\n",
    "            tqdm.write(f\"Epoch {epoch+1}: Train loss = {train_loss_mean:.5f}, Val loss = {val_loss:.5f}\")\n",
    "        \n",
    "        # Сохраняем модель, если val_loss < минимума val_loss\n",
    "        if val_loss < val_loss_min:\n",
    "            val_loss_min = val_loss\n",
    "            best_model_state = {k: v.cpu() for k, v in model.state_dict().items()}\n",
    "            torch.save(best_model_state, \"best_model.pth\")\n",
    "            tqdm.write(f\"Best model saved at epoch {epoch+1} (val_loss < minimal val_loss)\")\n",
    "\n",
    "    # Графики на каждой эпохе\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(epoch_train_losses, label=\"Train Loss\")\n",
    "    plt.plot(epoch_val_losses, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss (MSE)\")\n",
    "    plt.title(\"Train & Validation Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return epoch_train_losses, epoch_val_losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:08:20.424502Z",
     "iopub.status.busy": "2025-05-29T19:08:20.424202Z",
     "iopub.status.idle": "2025-05-29T19:08:20.447375Z",
     "shell.execute_reply": "2025-05-29T19:08:20.446518Z",
     "shell.execute_reply.started": "2025-05-29T19:08:20.424480Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchTSTForPrediction(\n",
       "  (model): PatchTSTModel(\n",
       "    (scaler): PatchTSTScaler(\n",
       "      (scaler): PatchTSTStdScaler()\n",
       "    )\n",
       "    (patchifier): PatchTSTPatchify()\n",
       "    (masking): Identity()\n",
       "    (encoder): PatchTSTEncoder(\n",
       "      (embedder): PatchTSTEmbedding(\n",
       "        (input_embedding): Linear(in_features=1, out_features=32, bias=True)\n",
       "      )\n",
       "      (positional_encoder): PatchTSTPositionalEncoding(\n",
       "        (positional_dropout): Identity()\n",
       "      )\n",
       "      (layers): ModuleList(\n",
       "        (0-2): 3 x PatchTSTEncoderLayer(\n",
       "          (self_attn): PatchTSTAttention(\n",
       "            (k_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (v_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (q_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "            (out_proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "          )\n",
       "          (dropout_path1): Identity()\n",
       "          (norm_sublayer1): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "          (ff): Sequential(\n",
       "            (0): Linear(in_features=32, out_features=512, bias=True)\n",
       "            (1): GELUActivation()\n",
       "            (2): Identity()\n",
       "            (3): Linear(in_features=512, out_features=32, bias=True)\n",
       "          )\n",
       "          (dropout_path3): Identity()\n",
       "          (norm_sublayer3): PatchTSTBatchNorm(\n",
       "            (batchnorm): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (head): PatchTSTPredictionHead(\n",
       "    (flatten): Flatten(start_dim=2, end_dim=-1)\n",
       "    (projection): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_len = 20  \n",
    "\n",
    "config = PatchTSTConfig(\n",
    "    context_length=seq_len,\n",
    "    prediction_length=1,\n",
    "    patch_len=10,        \n",
    "    d_model=32, # размерность скрытого пространства\n",
    "    n_heads=20,\n",
    "    n_layers=100,\n",
    "    target_dim=1,\n",
    "    channels=1,\n",
    "    head_dropout=0.1\n",
    ")\n",
    "\n",
    "model = PatchTSTForPrediction(config)\n",
    "model.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-29T19:08:24.447976Z",
     "iopub.status.busy": "2025-05-29T19:08:24.447627Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9064302abb1e499197012d2ab5da7fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss = 1.52930, Val loss = 8.77559\n",
      "Best model saved at epoch 1 (val_loss < minimal val_loss)\n"
     ]
    }
   ],
   "source": [
    "train_loss, val_loss = pretrain_model(model, train_dl, val_dl, 100, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = PatchTSTForPrediction(config)\n",
    "state_dict = torch.load('/kaggle/working/best_model.pth', map_location='cpu')\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        outputs = model(xb)\n",
    "        preds = outputs.prediction_outputs.squeeze(-1).squeeze(-1).cpu().numpy()\n",
    "        all_preds.append(preds)\n",
    "        all_targets.append(yb.cpu().numpy())\n",
    "        \n",
    "y_pred = np.concatenate(all_preds)\n",
    "y_true = np.concatenate(all_targets)\n",
    "\n",
    "print(f\"MAE: {mean_absolute_error(y_true, y_pred):.4f}\")\n",
    "print(f\"MSE: {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "print(f\"MAPE: {mean_absolute_percentage_error(y_true, y_pred):.4f}\")\n",
    "naive_preds = np.zeros_like(y_true)\n",
    "print(f\"MAE naive: {mean_absolute_error(y_true, naive_preds):.4f}\")\n",
    "print(f\"MSE naive: {mean_squared_error(y_true, naive_preds):.4f}\")\n",
    "print(f\"MAPE naive: {mean_absolute_percentage_error(y_true, naive_preds):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.plot(y_pred, label = \"Forecaster predictions\")\n",
    "plt.plot(y_true, label = \"True series\")\n",
    "plt.plot(naive_preds, label = \"Naive\")\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 7371208,
     "sourceId": 11874054,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
